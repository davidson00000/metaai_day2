# main.py - SerpAPI with ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿæ§‹ã¤ã

from langchain_community.utilities import SerpAPIWrapper
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain_community.chat_models import ChatOpenAI
from dotenv import load_dotenv
import os
import json
import hashlib

# ğŸ” ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["SERPAPI_API_KEY"] = os.getenv("SERPAPI_API_KEY")

# ğŸ” ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãæ¤œç´¢é–¢æ•°
def cached_search(query: str) -> str:
    cache_file = "search_cache.json"
    key = hashlib.sha256(query.encode()).hexdigest()

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    if os.path.exists(cache_file):
        with open(cache_file, "r", encoding="utf-8") as f:
            cache = json.load(f)
    else:
        cache = {}

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚Œã°è¿”ã™
    if key in cache:
        print(f"[Cache Hit] {query}")
        return cache[key]

    # SerpAPIå®Ÿè¡Œï¼ˆåˆå›ï¼‰
    print(f"[Cache Miss] {query} â†’ SerpAPI å®Ÿè¡Œ")
    search = SerpAPIWrapper()
    result = search.run(query)

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    cache[key] = result
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

    return result

# ğŸ›  ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãé–¢æ•°ã‚’ä½¿ã†ï¼‰
tools = [
    Tool(
        name="Google Search (cached)",
        func=cached_search,
        description="æ¤œç´¢çµæœã‚’å–å¾—ã™ã‚‹ã€‚çµæœã¯è‡ªå‹•ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€åŒã˜æ¤œç´¢ã§ã¯APIã‚’ä½¿ã‚ãªã„ã€‚"
    )
]

# ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹ç¯‰
llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ğŸ¯ å®Ÿè¡Œ
response = agent.run("AGIã¨ã¯ä½•ã‹ã‚’ç°¡å˜ã«3è¡Œã§æ•™ãˆã¦")
print("\nğŸ§  Final Answer:\n" + response)
